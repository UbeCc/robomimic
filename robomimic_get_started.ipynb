{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrbsbN3TtXmJ"
      },
      "source": [
        "## Robomimic Get Started Tutorial\n",
        "\n",
        "This notebook implements a simple training loop without the extensive features offered in robomimic such as logging and hyperparameter sweeping. Please refer to the [repository](https://github.com/ARISE-Initiative/robomimic) and the [documentation](https://robomimic.github.io/docs/introduction/overview.html) for the full set of features and the rest of the pipeline.\n",
        "\n",
        "This notebook includes the following tutorials:\n",
        "\n",
        "1. Set up robomimic development environment\n",
        "2. Downloading task-specific dataset\n",
        "3. Create a naive behavior cloning policy\n",
        "4. Setup a simple training loop\n",
        "5. Run policy training\n",
        "6. Visualize the trained policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxIvWhDJGY52"
      },
      "source": [
        "###0. Use GPU to accelerate training\n",
        "\n",
        "To use GPU runtime, click runtime on the top navigation part -> change runtime type -> select GPU as your accelerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbgiD1mkuGWZ"
      },
      "source": [
        "### 1. Set up development environment\n",
        "\n",
        "The main dependencies of robomimic are\n",
        "- torch\n",
        "- numpy\n",
        "- h5py\n",
        "- robosuite\n",
        "- mujoco\n",
        "- tensorbordX\n",
        "- egl_probe\n",
        "- matplotlib\n",
        "\n",
        "\n",
        "The full list is included in the requirements.txt file in the repo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1aZtB-M2DhV"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9Zw4cH9u4ZDv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/'\n",
            "/home/wanghaoran/robomimic\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# First, we need to decide where to host the runtime storage\n",
        "USE_GDRIVE_STORAGE = False\n",
        "\n",
        "if not USE_GDRIVE_STORAGE:\n",
        "    # Option 1: use the colab runtime storage. All trained model and downloaded\n",
        "    # will disappear after you disconnect from the runtime.\n",
        "    WS_DIR = \"/content/\"\n",
        "else:\n",
        "    # Option 2: use your google drive as the runtime storage. You need to grant\n",
        "    # permission for the colab runtime to access your google drive. You also\n",
        "    # need to decide on a workspace for robomimic\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    WS_DIR = \"PATH-TO-YOUR-WORKSPACE\" # this should be the absolute path, e.g., \"/content/drive/MyDrive/my-ws/\"\n",
        "    assert os.path.exists(WS_DIR)\n",
        "\n",
        "%cd $WS_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zvEgLOHNuFm6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'robomimic' already exists and is not an empty directory.\n",
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Obtaining file:///home/wanghaoran/robomimic/robomimic\n",
            "\u001b[31mERROR: file:///home/wanghaoran/robomimic/robomimic does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Clone the repo and install the basic requirements\n",
        "!git clone https://github.com/ARISE-Initiative/robomimic\n",
        "!pip install -e robomimic/\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('./robomimic/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT6VyAEUdZqc"
      },
      "source": [
        "**WARNING**: To exactly reproduce the setup from our study paper, mujoco and robosuite should be installed from source following the [instruction](https://robomimic.github.io/docs/introduction/installation.html#install-simulators) However, if you just want to train on our dataset, you could proceed with the\n",
        "following default setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iNFm_2JOv2xh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[sudo] password for wanghaoran: \n",
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Requirement already satisfied: mujoco in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (3.2.6)\n",
            "Requirement already satisfied: absl-py in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from mujoco) (2.1.0)\n",
            "Requirement already satisfied: etils[epath] in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from mujoco) (1.11.0)\n",
            "Requirement already satisfied: glfw in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from mujoco) (2.8.0)\n",
            "Requirement already satisfied: numpy in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from mujoco) (1.26.4)\n",
            "Requirement already satisfied: pyopengl in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from mujoco) (3.1.7)\n",
            "Requirement already satisfied: fsspec in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from etils[epath]->mujoco) (2024.12.0)\n",
            "Requirement already satisfied: importlib_resources in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from etils[epath]->mujoco) (6.4.5)\n",
            "Requirement already satisfied: typing_extensions in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from etils[epath]->mujoco) (4.12.2)\n",
            "Requirement already satisfied: zipp in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from etils[epath]->mujoco) (3.21.0)\n",
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Requirement already satisfied: robosuite in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from robosuite) (1.26.4)\n",
            "Requirement already satisfied: numba>=0.49.1 in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from robosuite) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.2.3 in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from robosuite) (1.14.1)\n",
            "Requirement already satisfied: mujoco>=3.2.3 in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from robosuite) (3.2.6)\n",
            "Requirement already satisfied: mink>=0.0.5 in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from robosuite) (0.0.5)\n",
            "Requirement already satisfied: Pillow in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from robosuite) (11.0.0)\n",
            "Requirement already satisfied: opencv-python in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from robosuite) (4.10.0.84)\n",
            "Requirement already satisfied: pynput in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from robosuite) (1.7.7)\n",
            "Requirement already satisfied: termcolor in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from robosuite) (2.5.0)\n",
            "Requirement already satisfied: pytest in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from robosuite) (8.3.4)\n",
            "Requirement already satisfied: qpsolvers>=4.3.1 in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from qpsolvers[quadprog]>=4.3.1->mink>=0.0.5->robosuite) (4.4.0)\n",
            "Requirement already satisfied: typing_extensions in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from mink>=0.0.5->robosuite) (4.12.2)\n",
            "Requirement already satisfied: absl-py in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from mujoco>=3.2.3->robosuite) (2.1.0)\n",
            "Requirement already satisfied: etils[epath] in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from mujoco>=3.2.3->robosuite) (1.11.0)\n",
            "Requirement already satisfied: glfw in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from mujoco>=3.2.3->robosuite) (2.8.0)\n",
            "Requirement already satisfied: pyopengl in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from mujoco>=3.2.3->robosuite) (3.1.7)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from numba>=0.49.1->robosuite) (0.43.0)\n",
            "Requirement already satisfied: six in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from pynput->robosuite) (1.17.0)\n",
            "Requirement already satisfied: evdev>=1.3 in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from pynput->robosuite) (1.7.1)\n",
            "Requirement already satisfied: python-xlib>=0.17 in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from pynput->robosuite) (0.33)\n",
            "Requirement already satisfied: iniconfig in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from pytest->robosuite) (2.0.0)\n",
            "Requirement already satisfied: packaging in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from pytest->robosuite) (24.2)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from pytest->robosuite) (1.5.0)\n",
            "Requirement already satisfied: quadprog>=0.1.11 in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from qpsolvers[quadprog]>=4.3.1->mink>=0.0.5->robosuite) (0.1.13)\n",
            "Requirement already satisfied: fsspec in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from etils[epath]->mujoco>=3.2.3->robosuite) (2024.12.0)\n",
            "Requirement already satisfied: importlib_resources in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from etils[epath]->mujoco>=3.2.3->robosuite) (6.4.5)\n",
            "Requirement already satisfied: zipp in /home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages (from etils[epath]->mujoco>=3.2.3->robosuite) (3.21.0)\n"
          ]
        }
      ],
      "source": [
        "# Install mujoco and robosuite\n",
        "import os\n",
        "\n",
        "# install all system dependencies for mujoco-py\n",
        "!sudo apt install curl git libgl1-mesa-dev libgl1-mesa-glx libglew-dev \\\n",
        "         libosmesa6-dev software-properties-common net-tools unzip vim \\\n",
        "         virtualenv wget xpra xserver-xorg-dev libglfw3-dev patchelf\n",
        "\n",
        "#install mujoco-py\n",
        "!pip install mujoco\n",
        "\n",
        "#install robosuite\n",
        "!pip install robosuite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DBq5a2V01uy"
      },
      "outputs": [],
      "source": [
        "# (Optional) test robomimic installation by running a dummy training loop\n",
        "!python robomimic/examples/train_bc_rnn.py --debug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi6QiLK410TV"
      },
      "source": [
        "## 2. Download demonstration dataset for a task\n",
        "\n",
        "For robomimic tasks, we organize the demonstration datasets by\n",
        "- task name (e.g., lift)\n",
        "- data source (ph - proficient human, mh - multi human, mg - machine-generated)\n",
        "- observation type (low_dim or image)\n",
        "\n",
        "For more details of the dataset structure, visit [robomimic documentation](https://robomimic.github.io/docs/datasets/robomimic_v0.1.html) and the [dataset tutorial](https://github.com/ARISE-Initiative/robomimic/blob/master/examples/notebooks/datasets.ipynb)\n",
        "\n",
        "\n",
        "Here we demonstrate downloading the proficient human (`ph`) dataset with low-dimensional (`low_dim`) observation for the `lift` task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ptx48ZOK2GpA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "low_dim_v141.hdf5: 21.7MB [00:04, 4.75MB/s]                            \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "import robomimic\n",
        "import robomimic.utils.file_utils as FileUtils\n",
        "\n",
        "# the dataset registry can be found at robomimic/__init__.py\n",
        "from robomimic import DATASET_REGISTRY\n",
        "\n",
        "WS_DIR = \"/home/wanghaoran/robomimic_data\"\n",
        "# set download folder and make it\n",
        "download_folder = WS_DIR + \"/robomimic_data/\"\n",
        "os.makedirs(download_folder, exist_ok=True)\n",
        "\n",
        "# download the dataset\n",
        "task = \"lift\"\n",
        "dataset_type = \"ph\"\n",
        "hdf5_type = \"low_dim\"\n",
        "FileUtils.download_url(\n",
        "    url=DATASET_REGISTRY[task][dataset_type][hdf5_type][\"url\"],\n",
        "    download_dir=download_folder,\n",
        ")\n",
        "\n",
        "# enforce that the dataset exists\n",
        "dataset_path = os.path.join(download_folder, \"low_dim_v141.hdf5\")\n",
        "assert os.path.exists(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "s3uh3-sc1XQ8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "total transitions: 9666\n",
            "total trajectories: 200\n",
            "traj length mean: 48.33\n",
            "traj length std: 6.116461395284041\n",
            "traj length min: 36\n",
            "traj length max: 64\n",
            "action min: -1.0\n",
            "action max: 1.0\n",
            "\n",
            "==== Filter Keys ====\n",
            "filter key 20_percent with 40 demos\n",
            "filter key 20_percent_train with 36 demos\n",
            "filter key 20_percent_valid with 4 demos\n",
            "filter key 50_percent with 100 demos\n",
            "filter key 50_percent_train with 90 demos\n",
            "filter key 50_percent_valid with 10 demos\n",
            "filter key train with 180 demos\n",
            "filter key valid with 20 demos\n",
            "\n",
            "==== Env Meta ====\n",
            "{\n",
            "    \"env_name\": \"Lift\",\n",
            "    \"env_version\": \"1.4.1\",\n",
            "    \"type\": 1,\n",
            "    \"env_kwargs\": {\n",
            "        \"has_renderer\": false,\n",
            "        \"has_offscreen_renderer\": false,\n",
            "        \"ignore_done\": true,\n",
            "        \"use_object_obs\": true,\n",
            "        \"use_camera_obs\": false,\n",
            "        \"control_freq\": 20,\n",
            "        \"controller_configs\": {\n",
            "            \"type\": \"OSC_POSE\",\n",
            "            \"input_max\": 1,\n",
            "            \"input_min\": -1,\n",
            "            \"output_max\": [\n",
            "                0.05,\n",
            "                0.05,\n",
            "                0.05,\n",
            "                0.5,\n",
            "                0.5,\n",
            "                0.5\n",
            "            ],\n",
            "            \"output_min\": [\n",
            "                -0.05,\n",
            "                -0.05,\n",
            "                -0.05,\n",
            "                -0.5,\n",
            "                -0.5,\n",
            "                -0.5\n",
            "            ],\n",
            "            \"kp\": 150,\n",
            "            \"damping\": 1,\n",
            "            \"impedance_mode\": \"fixed\",\n",
            "            \"kp_limits\": [\n",
            "                0,\n",
            "                300\n",
            "            ],\n",
            "            \"damping_limits\": [\n",
            "                0,\n",
            "                10\n",
            "            ],\n",
            "            \"position_limits\": null,\n",
            "            \"orientation_limits\": null,\n",
            "            \"uncouple_pos_ori\": true,\n",
            "            \"control_delta\": true,\n",
            "            \"interpolation\": null,\n",
            "            \"ramp_ratio\": 0.2\n",
            "        },\n",
            "        \"robots\": [\n",
            "            \"Panda\"\n",
            "        ],\n",
            "        \"camera_depths\": false,\n",
            "        \"camera_heights\": 84,\n",
            "        \"camera_widths\": 84,\n",
            "        \"reward_shaping\": false\n",
            "    }\n",
            "}\n",
            "\n",
            "==== Dataset Structure ====\n",
            "episode demo_0 with 59 transitions\n",
            "    key: actions with shape (59, 7)\n",
            "    key: dones with shape (59,)\n",
            "    key: next_obs\n",
            "        observation key object with shape (59, 10)\n",
            "        observation key robot0_eef_pos with shape (59, 3)\n",
            "        observation key robot0_eef_quat with shape (59, 4)\n",
            "        observation key robot0_eef_vel_ang with shape (59, 3)\n",
            "        observation key robot0_eef_vel_lin with shape (59, 3)\n",
            "        observation key robot0_gripper_qpos with shape (59, 2)\n",
            "        observation key robot0_gripper_qvel with shape (59, 2)\n",
            "        observation key robot0_joint_pos with shape (59, 7)\n",
            "        observation key robot0_joint_pos_cos with shape (59, 7)\n",
            "        observation key robot0_joint_pos_sin with shape (59, 7)\n",
            "        observation key robot0_joint_vel with shape (59, 7)\n",
            "    key: obs\n",
            "        observation key object with shape (59, 10)\n",
            "        observation key robot0_eef_pos with shape (59, 3)\n",
            "        observation key robot0_eef_quat with shape (59, 4)\n",
            "        observation key robot0_eef_vel_ang with shape (59, 3)\n",
            "        observation key robot0_eef_vel_lin with shape (59, 3)\n",
            "        observation key robot0_gripper_qpos with shape (59, 2)\n",
            "        observation key robot0_gripper_qvel with shape (59, 2)\n",
            "        observation key robot0_joint_pos with shape (59, 7)\n",
            "        observation key robot0_joint_pos_cos with shape (59, 7)\n",
            "        observation key robot0_joint_pos_sin with shape (59, 7)\n",
            "        observation key robot0_joint_vel with shape (59, 7)\n",
            "    key: rewards with shape (59,)\n",
            "    key: states with shape (59, 32)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Here we can print out the data metadata\n",
        "!python robomimic/scripts/get_dataset_info.py --dataset $dataset_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovLnbr8M4RzP"
      },
      "source": [
        "## 3. Build a simple behavior cloning model\n",
        "\n",
        "Follows the default hyperparameter in `robomimic/config/bc_config.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VWIpC-Ob5VQp"
      },
      "outputs": [],
      "source": [
        "# import all utility functions\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import robomimic\n",
        "import robomimic.utils.obs_utils as ObsUtils\n",
        "import robomimic.utils.torch_utils as TorchUtils\n",
        "import robomimic.utils.test_utils as TestUtils\n",
        "import robomimic.utils.file_utils as FileUtils\n",
        "import robomimic.utils.train_utils as TrainUtils\n",
        "from robomimic.utils.dataset import SequenceDataset\n",
        "\n",
        "from robomimic.config import config_factory\n",
        "from robomimic.algo import algo_factory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4fOznEH44g2g"
      },
      "outputs": [],
      "source": [
        "def get_example_model(dataset_path, device):\n",
        "    \"\"\"\n",
        "    Use a default config to construct a BC model.\n",
        "    \"\"\"\n",
        "\n",
        "    # default BC config\n",
        "    config = config_factory(algo_name=\"bc\")\n",
        "\n",
        "    # read config to set up metadata for observation modalities (e.g. detecting rgb observations)\n",
        "    ObsUtils.initialize_obs_utils_with_config(config)\n",
        "\n",
        "    # read dataset to get some metadata for constructing model\n",
        "    # all_obs_keys determines what observations we will feed to the policy\n",
        "    shape_meta = FileUtils.get_shape_metadata_from_dataset(\n",
        "        dataset_path=dataset_path,\n",
        "        all_obs_keys=sorted((\n",
        "            \"robot0_eef_pos\",  # robot end effector position\n",
        "            \"robot0_eef_quat\",   # robot end effector rotation (in quaternion)\n",
        "            \"robot0_gripper_qpos\",   # parallel gripper joint position\n",
        "            \"object\",  # object information\n",
        "        )),\n",
        "    )\n",
        "\n",
        "    # make BC model\n",
        "    model = algo_factory(\n",
        "        algo_name=config.algo_name,\n",
        "        config=config,\n",
        "        obs_key_shapes=shape_meta[\"all_shapes\"],\n",
        "        ac_dim=shape_meta[\"ac_dim\"],\n",
        "        device=device,\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "R_3knZqd4pGa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============= Initialized Observation Utils with Obs Spec =============\n",
            "\n",
            "using obs modality: low_dim with keys: ['robot0_eef_pos', 'object', 'robot0_eef_quat', 'robot0_gripper_qpos']\n",
            "using obs modality: rgb with keys: []\n",
            "using obs modality: depth with keys: []\n",
            "using obs modality: scan with keys: []\n",
            "ObservationKeyToModalityDict: action not found, adding action to mapping with assumed low_dim modality!\n",
            "BC (\n",
            "  ModuleDict(\n",
            "    (policy): ActorNetwork(\n",
            "        action_dim=7\n",
            "  \n",
            "        encoder=ObservationGroupEncoder(\n",
            "            group=obs\n",
            "            ObservationEncoder(\n",
            "                Key(\n",
            "                    name=object\n",
            "                    shape=[10]\n",
            "                    modality=low_dim\n",
            "                    randomizer=None\n",
            "                    net=None\n",
            "                    sharing_from=None\n",
            "                )\n",
            "                Key(\n",
            "                    name=robot0_eef_pos\n",
            "                    shape=[3]\n",
            "                    modality=low_dim\n",
            "                    randomizer=None\n",
            "                    net=None\n",
            "                    sharing_from=None\n",
            "                )\n",
            "                Key(\n",
            "                    name=robot0_eef_quat\n",
            "                    shape=[4]\n",
            "                    modality=low_dim\n",
            "                    randomizer=None\n",
            "                    net=None\n",
            "                    sharing_from=None\n",
            "                )\n",
            "                Key(\n",
            "                    name=robot0_gripper_qpos\n",
            "                    shape=[2]\n",
            "                    modality=low_dim\n",
            "                    randomizer=None\n",
            "                    net=None\n",
            "                    sharing_from=None\n",
            "                )\n",
            "                output_shape=[19]\n",
            "            )\n",
            "        )\n",
            "  \n",
            "        mlp=MLP(\n",
            "            input_dim=19\n",
            "            output_dim=1024\n",
            "            layer_dims=(1024,)\n",
            "            layer_func=Linear\n",
            "            dropout=None\n",
            "            act=ReLU\n",
            "            output_act=ReLU\n",
            "        )\n",
            "  \n",
            "        decoder=ObservationDecoder(\n",
            "            Key(\n",
            "                name=action\n",
            "                shape=(7,)\n",
            "                modality=low_dim\n",
            "                net=(Linear(in_features=1024, out_features=7, bias=True))\n",
            "            )\n",
            "        )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/wanghaoran/miniconda3/envs/robomimic/lib/python3.11/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
            "  return torch._C._cuda_getDeviceCount() > 0\n"
          ]
        }
      ],
      "source": [
        "device = TorchUtils.get_torch_device(try_to_use_cuda=True)\n",
        "model = get_example_model(dataset_path, device=device)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxa1d9Te3CUm"
      },
      "source": [
        "## 4. Build a simple training loop\n",
        "\n",
        "Here we build a simple data loader pipeline and a training loop. Note that this code snippet is only instructional and is a stripped-down version of robomimic's main training loop (`robomimic/scripts/train.py`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xkxeqO3B37YG"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "WARNING: This code snippet is only for instructive purposes, and is missing several useful\n",
        "         components used during training such as logging and rollout evaluation.\n",
        "\"\"\"\n",
        "def get_data_loader(dataset_path):\n",
        "    \"\"\"\n",
        "    Get a data loader to sample batches of data.\n",
        "    Args:\n",
        "        dataset_path (str): path to the dataset hdf5\n",
        "    \"\"\"\n",
        "    dataset = SequenceDataset(\n",
        "        hdf5_path=dataset_path,\n",
        "        obs_keys=(                      # observations we want to appear in batches\n",
        "            \"robot0_eef_pos\",\n",
        "            \"robot0_eef_quat\",\n",
        "            \"robot0_gripper_qpos\",\n",
        "            \"object\",\n",
        "        ),\n",
        "        dataset_keys=(                  # can optionally specify more keys here if they should appear in batches\n",
        "            \"actions\",\n",
        "            \"rewards\",\n",
        "            \"dones\",\n",
        "        ),\n",
        "        load_next_obs=True,\n",
        "        frame_stack=1,\n",
        "        seq_length=10,                  # length-10 temporal sequences\n",
        "        pad_frame_stack=True,\n",
        "        pad_seq_length=True,            # pad last obs per trajectory to ensure all sequences are sampled\n",
        "        get_pad_mask=False,\n",
        "        goal_mode=None,\n",
        "        hdf5_cache_mode=\"all\",          # cache dataset in memory to avoid repeated file i/o\n",
        "        hdf5_use_swmr=True,\n",
        "        hdf5_normalize_obs=False,\n",
        "        filter_by_attribute=None,       # can optionally provide a filter key here\n",
        "    )\n",
        "    print(\"\\n============= Created Dataset =============\")\n",
        "    print(dataset)\n",
        "    print(\"\")\n",
        "\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        sampler=None,       # no custom sampling logic (uniform sampling)\n",
        "        batch_size=100,     # batches of size 100\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        drop_last=True      # don't provide last batch in dataset pass if it's less than 100 in size\n",
        "    )\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "def run_train_loop(model, data_loader, num_epochs=50, gradient_steps_per_epoch=100):\n",
        "    \"\"\"\n",
        "    Note: this is a stripped down version of @TrainUtils.run_epoch and the train loop\n",
        "    in the train function in train.py. Logging and evaluation rollouts were removed.\n",
        "    Args:\n",
        "        model (Algo instance): instance of Algo class to use for training\n",
        "        data_loader (torch.utils.data.DataLoader instance): torch DataLoader for\n",
        "            sampling batches\n",
        "    \"\"\"\n",
        "    # ensure model is in train mode\n",
        "    model.set_train()\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1): # epoch numbers start at 1\n",
        "\n",
        "        # iterator for data_loader - it yields batches\n",
        "        data_loader_iter = iter(data_loader)\n",
        "\n",
        "        # record losses\n",
        "        losses = []\n",
        "\n",
        "        for _ in range(gradient_steps_per_epoch):\n",
        "\n",
        "            # load next batch from data loader\n",
        "            try:\n",
        "                batch = next(data_loader_iter)\n",
        "            except StopIteration:\n",
        "                # data loader ran out of batches - reset and yield first batch\n",
        "                data_loader_iter = iter(data_loader)\n",
        "                batch = next(data_loader_iter)\n",
        "\n",
        "            # process batch for training\n",
        "            input_batch = model.process_batch_for_training(batch)\n",
        "\n",
        "            # forward and backward pass\n",
        "            info = model.train_on_batch(batch=input_batch, epoch=epoch, validate=False)\n",
        "\n",
        "            # record loss\n",
        "            step_log = model.log_info(info)\n",
        "            losses.append(step_log[\"Loss\"])\n",
        "\n",
        "        # do anything model needs to after finishing epoch\n",
        "        model.on_epoch_end(epoch)\n",
        "\n",
        "        print(\"Train Epoch {}: Loss {}\".format(epoch, np.mean(losses)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUeL98Qr6lfU"
      },
      "source": [
        "## 5. Run policy training\n",
        "\n",
        "Using the model and the training loop defined above. Note that this simple training loop does not save checkpoint. For model checkpointing, take a look at the full-feature [training loop](https://github.com/ARISE-Initiative/robomimic/blob/master/robomimic/scripts/train.py#L290) and the [documentation](https://robomimic.github.io/docs/tutorials/viewing_results.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_aZq79x74J1B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SequenceDataset: loading dataset into memory...\n",
            "100%|██████████| 200/200 [00:00<00:00, 839.24it/s]\n",
            "SequenceDataset: caching get_item calls...\n",
            "100%|██████████| 9666/9666 [00:00<00:00, 14241.80it/s]\n",
            "\n",
            "============= Created Dataset =============\n",
            "SequenceDataset (\n",
            "\tpath=/home/wanghaoran/robomimic_data/robomimic_data/low_dim_v141.hdf5\n",
            "\tobs_keys=('robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos', 'object')\n",
            "\tseq_length=10\n",
            "\tfilter_key=none\n",
            "\tframe_stack=1\n",
            "\tpad_seq_length=True\n",
            "\tpad_frame_stack=True\n",
            "\tgoal_mode=none\n",
            "\tcache_mode=all\n",
            "\tnum_demos=200\n",
            "\tnum_sequences=9666\n",
            ")\n",
            "\n",
            "Train Epoch 1: Loss 0.15518127389252187\n",
            "Train Epoch 2: Loss 0.10966934517025947\n",
            "Train Epoch 3: Loss 0.08010900542140006\n",
            "Train Epoch 4: Loss 0.06487624868750572\n",
            "Train Epoch 5: Loss 0.055483538918197156\n",
            "Train Epoch 6: Loss 0.049927784986794\n",
            "Train Epoch 7: Loss 0.04550415605306626\n",
            "Train Epoch 8: Loss 0.04440727833658457\n",
            "Train Epoch 9: Loss 0.041011664159595965\n",
            "Train Epoch 10: Loss 0.039067299552261826\n",
            "Train Epoch 11: Loss 0.03819495365023613\n",
            "Train Epoch 12: Loss 0.03707380931824446\n",
            "Train Epoch 13: Loss 0.03551011273637414\n",
            "Train Epoch 14: Loss 0.034725120645016434\n",
            "Train Epoch 15: Loss 0.03421963093802333\n",
            "Train Epoch 16: Loss 0.033192910719662905\n",
            "Train Epoch 17: Loss 0.032850742638111115\n",
            "Train Epoch 18: Loss 0.03183491125702858\n",
            "Train Epoch 19: Loss 0.031359858866781\n",
            "Train Epoch 20: Loss 0.03162378203123808\n",
            "Train Epoch 21: Loss 0.030489601101726292\n",
            "Train Epoch 22: Loss 0.029670609459280968\n",
            "Train Epoch 23: Loss 0.02926538672298193\n",
            "Train Epoch 24: Loss 0.029299775660037993\n",
            "Train Epoch 25: Loss 0.028915527947247027\n",
            "Train Epoch 26: Loss 0.02879029270261526\n",
            "Train Epoch 27: Loss 0.028273974247276783\n",
            "Train Epoch 28: Loss 0.02760673761367798\n",
            "Train Epoch 29: Loss 0.027935701571404934\n",
            "Train Epoch 30: Loss 0.027879936564713718\n",
            "Train Epoch 31: Loss 0.027155503993853927\n",
            "Train Epoch 32: Loss 0.027480519134551285\n",
            "Train Epoch 33: Loss 0.026888386383652686\n",
            "Train Epoch 34: Loss 0.026753778364509345\n",
            "Train Epoch 35: Loss 0.02670168651267886\n",
            "Train Epoch 36: Loss 0.026761369779706\n",
            "Train Epoch 37: Loss 0.02627700613811612\n",
            "Train Epoch 38: Loss 0.026280395174399018\n",
            "Train Epoch 39: Loss 0.025849351817741992\n",
            "Train Epoch 40: Loss 0.026205034796148538\n",
            "Train Epoch 41: Loss 0.025464763585478067\n",
            "Train Epoch 42: Loss 0.025452350936830043\n",
            "Train Epoch 43: Loss 0.025374882174655795\n",
            "Train Epoch 44: Loss 0.025513712670654057\n",
            "Train Epoch 45: Loss 0.02553978024981916\n",
            "Train Epoch 46: Loss 0.024894497599452736\n",
            "Train Epoch 47: Loss 0.024751588208600878\n",
            "Train Epoch 48: Loss 0.025791089870035647\n",
            "Train Epoch 49: Loss 0.025585504062473775\n",
            "Train Epoch 50: Loss 0.02508599082008004\n"
          ]
        }
      ],
      "source": [
        "# get dataset loader\n",
        "data_loader = get_data_loader(dataset_path=dataset_path)\n",
        "\n",
        "# run training loop\n",
        "run_train_loop(model=model, data_loader=data_loader, num_epochs=50, gradient_steps_per_epoch=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GozrJNd7-s8"
      },
      "source": [
        "## 6. Evaluate and visualize trained policy\n",
        "\n",
        "Here we execute the trained policy `model` in a simulated environment and play the rollout video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9Oe1qveJxE3"
      },
      "outputs": [],
      "source": [
        "# create simulation environment\n",
        "\n",
        "import robomimic.utils.env_utils as EnvUtils\n",
        "\n",
        "env_meta = FileUtils.get_env_metadata_from_dataset(dataset_path)\n",
        "\n",
        "env = EnvUtils.create_env_from_metadata(\n",
        "    env_meta=env_meta,\n",
        "    env_name=env_meta[\"env_name\"],\n",
        "    render=False,\n",
        "    render_offscreen=True,\n",
        "    use_image_obs=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yboDeTXi7Qxz"
      },
      "outputs": [],
      "source": [
        "from robomimic.algo import RolloutPolicy\n",
        "from robomimic.utils.train_utils import run_rollout\n",
        "import imageio\n",
        "\n",
        "# create a thin wrapper around the model to interact with the environment\n",
        "policy = RolloutPolicy(model)\n",
        "\n",
        "# create a video writer\n",
        "video_path = \"rollout.mp4\"\n",
        "video_writer = imageio.get_writer(video_path, fps=20)\n",
        "\n",
        "# run rollout\n",
        "rollout_log = run_rollout(\n",
        "    policy=policy,\n",
        "    env=env,\n",
        "    horizon=200,\n",
        "    video_writer=video_writer,\n",
        "    render=False\n",
        ")\n",
        "\n",
        "video_writer.close()\n",
        "# print rollout results\n",
        "print(rollout_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm35ompoQ3V6"
      },
      "outputs": [],
      "source": [
        "# visualize rollout video\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open(video_path, \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAVQQTf6SL7T"
      },
      "source": [
        "## What's next?\n",
        "\n",
        "Now that you understand the basic components of robomimic, it's time to delve deeper into each component by reading up the [documentation site](https://robomimic.github.io/docs/introduction/overview.html). Robomimic offers a rich set of utilities for model building, training loop management, model checkpointing, visualization, hyper-parameter sweeping, and logging. You can get to more about each component by following the provided the examples and tutorials.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "robomimic",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
